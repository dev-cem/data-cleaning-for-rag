{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code base was used to clean the sierra_db in order for the RAG to be more efficent. To be able to run it \n",
    "1. pip install -r requirments.txt\n",
    "2. Create a .env file with \"OPEN_AI_KEY\" and you API key as value\n",
    "3. Create a folder \"data\" in which you will put the raw dataset to clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = 'data/sierra_db.csv'\n",
    "\n",
    "# Read the CSV file with specified dtypes\n",
    "data = pd.read_csv(csv_file_path, dtype={'column_name_2': str, 'column_name_3': str, 'column_name_4': str, 'column_name_6': str}, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 94654\n"
     ]
    }
   ],
   "source": [
    "results = data[['UniqueUserReference', 'QuestionDate', 'UserQuestion']]\n",
    "print(\"Total data:\", len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1, 2 Remove Duplicates and empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 14\n",
      "Number of rows after removing duplicates: 94640\n",
      "Number of columns after removing empty columns: 94640\n"
     ]
    }
   ],
   "source": [
    "# Call the OpenAI API and prompt with UserQuestion and store the ModelAnswer\n",
    "# Display all duplicates\n",
    "duplicates = results[results.duplicated()]\n",
    "print(f\"Number of duplicate rows: {len(duplicates)}\")\n",
    "\n",
    "# Keep only one instance of each duplicate\n",
    "results = results.drop_duplicates()\n",
    "print(f\"Number of rows after removing duplicates: {len(results)}\")\n",
    "\n",
    "# Remove empty columns\n",
    "results = results.dropna(axis=1, how='all')\n",
    "print(f\"Number of columns after removing empty columns: {len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Filter Very Short Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering very short questions: 87925\n"
     ]
    }
   ],
   "source": [
    "results = results[results['UserQuestion'].str.len() > 10]\n",
    "print(f\"Number of rows after filtering very short questions: {len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Remove Spams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after cleaning text: 86394\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove excessive use of special characters\n",
    "    text = re.sub(r'[@#$%&]+', '', text)\n",
    "    # Remove repeated characters\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function and filter out rows where the text was modified\n",
    "results['CleanedUserQuestion'] = results['UserQuestion'].apply(clean_text)\n",
    "results = results[results['UserQuestion'] == results['CleanedUserQuestion']]\n",
    "\n",
    "# Drop the temporary 'CleanedUserQuestion' column\n",
    "results = results.drop(columns=['CleanedUserQuestion'])\n",
    "\n",
    "print(f\"Number of rows after cleaning text: {len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Remove Links and Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing links and emails: 86380\n"
     ]
    }
   ],
   "source": [
    "results = results[~results['UserQuestion'].str.contains(r'http://|https://|[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', na=False)]\n",
    "print(f\"Number of rows after removing links and emails: {len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Remove non English Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing non-English questions: 80250\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "results = results[results['UserQuestion'].apply(is_english)]\n",
    "print(f\"Number of rows after removing non-English questions: {len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaned Dataset is saved to sierra_db_cleaned,csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('sierra_db_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "openai.api_key = os.getenv(\"OPEN_AI_KEY\")\n",
    "\n",
    "def get_model_answer(question):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prompt each quesiton dated before 2024-10-15 16:22:50 trough gpt-4o-mini-2024-07-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sierra_db_4o_mini = pd.read_csv('sierra_db_4o_mini.csv')\n",
    "\n",
    "for index, row in tqdm(sierra_db_4o_mini.iterrows(), total=sierra_db_4o_mini.shape[0]):\n",
    "    if pd.isna(row['ModelAnswer']):\n",
    "        question_date = pd.to_datetime(row['QuestionDate'])\n",
    "        cutoff_date = pd.to_datetime('2024-10-15 16:22:50')\n",
    "        \n",
    "        if question_date > cutoff_date:\n",
    "            model_answer = data.loc[data['UniqueUserReference'] == row['UniqueUserReference'], 'ModelAnswer'].values[0]\n",
    "        else:\n",
    "            question = row['UserQuestion']\n",
    "            try:\n",
    "                model_answer = get_model_answer(question)\n",
    "                # Save the updated dataframe to the CSV file after each successful API call\n",
    "                sierra_db_4o_mini.to_csv('sierra_db_4o_mini.csv', index=False)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {index}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        sierra_db_4o_mini.at[index, 'ModelAnswer'] = model_answer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
